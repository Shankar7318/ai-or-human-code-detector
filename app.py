import streamlit as st
import pandas as pd
import numpy as np
import pickle
import os
from sklearn.preprocessing import StandardScaler
import json

# Set page config
st.set_page_config(
    page_title="Human vs AI Code Detector",
    page_icon="ðŸ¤–",
    layout="wide"
)

# Title and description
st.title("ðŸ¤– Human vs AI Code Detection")
st.markdown("""
This app uses machine learning to classify whether a code snippet was written by a human or generated by AI.
Upload a Python code file or paste your code below to analyze it.
""")

# Sidebar for model selection and info
with st.sidebar:
    st.header("Model Configuration")
    
    # Model selection
    model_choice = st.radio(
        "Select Model:",
        ["Random Forest", "Logistic Regression"]
    )
    
    st.markdown("---")
    st.header("About")
    st.markdown("""
    This model was trained on 1500 code samples (750 human, 750 AI) with features including:
    - Code length and complexity
    - Number of functions, classes, variables
    - Import statements and recursion usage
    - Loop structures and execution time
    """)

# Load models and scaler
@st.cache_resource
def load_models():
    """Load the trained models and scaler"""
    try:
        # Try to load saved models
        with open('rf_model.pkl', 'rb') as f:
            rf_model = pickle.load(f)
        
        with open('lr_model.pkl', 'rb') as f:
            lr_model = pickle.load(f)
            
        with open('scaler.pkl', 'rb') as f:
            scaler = pickle.load(f)
            
        return rf_model, lr_model, scaler
    except FileNotFoundError:
        st.error("Model files not found. Please ensure you have the trained models saved as rf_model.pkl, lr_model.pkl, and scaler.pkl in the same directory.")
        return None, None, None

# Feature extraction functions
def extract_features(code_snippet):
    """Extract features from a Python code snippet"""
    features = {}
    
    # Basic code metrics
    features['code_length'] = len(code_snippet)
    features['num_functions'] = code_snippet.count('def ')
    features['num_classes'] = code_snippet.count('class ')
    
    # Count variables (simple heuristic)
    features['num_variables'] = code_snippet.count(' = ') - code_snippet.count(' == ')
    
    # Comments
    features['num_comments'] = code_snippet.count('#')
    features['comment_density'] = features['num_comments'] / max(1, features['code_length'])
    
    # Imports
    features['num_imports'] = code_snippet.count('import ') + code_snippet.count('from ')
    
    # Recursion
    features['use_of_recursion'] = 1 if 'def ' in code_snippet and 'def ' in code_snippet[code_snippet.find('def ')+4:] else 0
    
    # Lambda functions
    features['use_of_lambda'] = 1 if 'lambda ' in code_snippet else 0
    
    # Loops
    features['num_loops'] = code_snippet.count('for ') + code_snippet.count('while ')
    
    # Complexity score (simple heuristic)
    complexity_score = 0
    complexity_score += features['num_functions'] * 2
    complexity_score += features['num_classes'] * 3
    complexity_score += features['num_loops']
    complexity_score += features['use_of_recursion'] * 3
    features['complexity_score'] = min(3, complexity_score)  # Cap at 3 like in dataset
    
    # Simulated execution time (based on complexity)
    features['execution_time'] = 1.0 + (complexity_score * 0.5) + (np.random.random() * 2)
    
    return features

# Main app functionality
def main():
    # Load models
    rf_model, lr_model, scaler = load_models()
    
    if rf_model is None:
        st.warning("""
        Models not loaded. You need to:
        1. Run the notebook to train the models
        2. Save them using pickle:
           ```python
           import pickle
           pickle.dump(rf_model, open('rf_model.pkl', 'wb'))
           pickle.dump(lr_model, open('lr_model.pkl', 'wb'))
           pickle.dump(scaler, open('scaler.pkl', 'wb'))
           ```
        """)
        return
    
    # Create tabs for different input methods
    tab1, tab2, tab3 = st.tabs(["ðŸ“ Paste Code", "ðŸ“ Upload File", "ðŸ“Š Sample Analysis"])
    
    with tab1:
        st.subheader("Paste Your Python Code")
        code_input = st.text_area(
            "Enter Python code:",
            height=200,
            placeholder="""def hello_world():
    # This is a sample function
    print("Hello, World!")
    return True"""
        )
        
        if st.button("Analyze Pasted Code", type="primary"):
            if code_input.strip():
                analyze_code(code_input, rf_model, lr_model, scaler, model_choice)
            else:
                st.warning("Please enter some code to analyze.")
    
    with tab2:
        st.subheader("Upload Python File")
        uploaded_file = st.file_uploader("Choose a .py file", type=['py'])
        
        if uploaded_file is not None:
            code_content = uploaded_file.read().decode("utf-8")
            
            # Show a preview
            with st.expander("Preview uploaded code"):
                st.code(code_content[:500] + ("..." if len(code_content) > 500 else ""))
            
            if st.button("Analyze Uploaded File", type="primary"):
                analyze_code(code_content, rf_model, lr_model, scaler, model_choice)
    
    with tab3:
        st.subheader("Sample Code Analysis")
        
        # Sample codes
        sample_codes = {
            "AI Generated (Simple)": """import random
def random_numbers(n): 
    return [random.randint(1, 100) for _ in range(n)]""",
            
            "Human Written (Simple)": """def add_numbers(a, b):
    return a + b
print(add_numbers(3, 4))""",
            
            "AI Generated (Complex)": """def factorial(n): 
    return 1 if n == 0 else n * factorial(n - 1)""",
            
            "Human Written (Complex)": """def fibonacci(n):
    sequence = [0, 1]
    for _ in range(n - 1):
        sequence.append(sequence[-1] + sequence[-2])
    return sequence[n]"""
        }
        
        selected_sample = st.selectbox(
            "Choose a sample code to analyze:",
            list(sample_codes.keys())
        )
        
        if selected_sample:
            st.code(sample_codes[selected_sample])
            
            if st.button("Analyze Sample", key="analyze_sample"):
                analyze_code(sample_codes[selected_sample], rf_model, lr_model, scaler, model_choice)

def analyze_code(code_snippet, rf_model, lr_model, scaler, model_choice):
    """Analyze the code and display results"""
    
    with st.spinner("Extracting features and analyzing..."):
        # Extract features
        features = extract_features(code_snippet)
        
        # Create DataFrame with same structure as training data
        feature_df = pd.DataFrame([features])
        
        # Ensure we have all expected columns in the right order
        expected_columns = [
            'code_length', 'num_functions', 'num_classes', 'num_variables',
            'num_comments', 'comment_density', 'num_imports', 'use_of_recursion',
            'use_of_lambda', 'num_loops', 'complexity_score', 'execution_time'
        ]
        
        # Reorder columns to match training data
        feature_df = feature_df[expected_columns]
        
        # Scale features
        features_scaled = scaler.transform(feature_df)
        
        # Make prediction
        if model_choice == "Random Forest":
            prediction = rf_model.predict(features_scaled)[0]
            proba = rf_model.predict_proba(features_scaled)[0]
        else:
            prediction = lr_model.predict(features_scaled)[0]
            proba = lr_model.predict_proba(features_scaled)[0]
        
        # Display results
        st.subheader("ðŸ” Analysis Results")
        
        # Create columns for results
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if prediction == 1:
                st.error("**Prediction: AI Generated** ðŸ¤–")
            else:
                st.success("**Prediction: Human Written** ðŸ‘¤")
        
        with col2:
            st.metric(
                label="AI Probability",
                value=f"{proba[1]*100:.1f}%"
            )
        
        with col3:
            st.metric(
                label="Human Probability",
                value=f"{proba[0]*100:.1f}%"
            )
        
        # Progress bars
        st.progress(float(proba[1]), text="AI Likelihood")
        st.progress(float(proba[0]), text="Human Likelihood")
        
        # Feature breakdown
        st.subheader("ðŸ“Š Feature Analysis")
        
        # Convert features to a more readable format
        feature_display = {
            "Code Length": f"{features['code_length']} characters",
            "Functions": features['num_functions'],
            "Classes": features['num_classes'],
            "Variables": features['num_variables'],
            "Imports": features['num_imports'],
            "Comments": features['num_comments'],
            "Loops": features['num_loops'],
            "Uses Recursion": "Yes" if features['use_of_recursion'] else "No",
            "Uses Lambda": "Yes" if features['use_of_lambda'] else "No",
            "Complexity Score": f"{features['complexity_score']}/3"
        }
        
        # Display features in columns
        cols = st.columns(3)
        for idx, (key, value) in enumerate(feature_display.items()):
            with cols[idx % 3]:
                st.metric(label=key, value=value)
        
        # Insights
        st.subheader("ðŸ’¡ Insights")
        
        insights = []
        if features['num_comments'] == 0:
            insights.append("No comments found - common in AI-generated code")
        
        if features['use_of_recursion']:
            insights.append("Uses recursion - more common in algorithm-focused AI code")
        
        if features['num_imports'] > 2:
            insights.append("Multiple imports - could indicate AI preference for libraries")
        
        if features['complexity_score'] < 1:
            insights.append("Low complexity - more typical of simple human code")
        
        if insights:
            for insight in insights:
                st.info(f"â€¢ {insight}")
        else:
            st.info("Code shows mixed characteristics - challenging to classify!")

# Additional pages/info
st.markdown("---")
with st.expander("ðŸ“ˆ Model Performance"):
    st.markdown("""
    ### Training Performance:
    - **Random Forest**: 100% accuracy on test set
    - **Logistic Regression**: 100% accuracy on test set
    
    ### Dataset Statistics:
    - Total samples: 1,500
    - Human-written: 750
    - AI-generated: 750
    - Features extracted: 12
    
    ### Note:
    These are perfect scores because the dataset was synthetically created.
    In real-world scenarios, expect lower but still strong performance.
    """)

with st.expander("ðŸ› ï¸ How It Works"):
    st.markdown("""
    ### Process:
    1. **Feature Extraction**: The app analyzes your code and extracts 12 different metrics
    2. **Scaling**: Features are normalized using the same scaler as during training
    3. **Prediction**: The selected model processes the features
    4. **Analysis**: Results are displayed with confidence scores
    
    ### Key Features Extracted:
    - Structural elements (functions, classes, loops)
    - Complexity metrics
    - Code patterns (recursion, lambdas)
    - Documentation density
    
    ### Limitations:
    - Works best with Python code
    - Accuracy depends on similarity to training data
    - Very short snippets may be harder to classify
    """)

if __name__ == "__main__":
    main()